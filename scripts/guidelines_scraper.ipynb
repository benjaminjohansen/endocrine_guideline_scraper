{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Define a translation table\n",
    "trans_table = str.maketrans('æøåÆØÅ', 'aoaAOA')\n",
    "\n",
    "# Trying with a dict instead\n",
    "translate_dict = {\n",
    "    \"æ\":\"ae\",\n",
    "    \"ø\":\"oe\",\n",
    "    \"å\":\"aa\",\n",
    "    \"Æ\":\"AE\",\n",
    "    \"Ø\":\"OE\",\n",
    "    \"Å\":\"AA\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Get all guideline links and from a collection. Also get the titel of the guideline\n",
    "2. For each guideline make a file named the same as the guideline seperated by _, and save all the content to the file.\n",
    "3. TODO: Make tests to check if there has been updates to the guidelines. Start a manual loop to figure out which guideline should be used. \n",
    "\n",
    "## Get all guidelins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://endocrinology.dk/nbv/diabetes-melitus/\"\n",
    "\n",
    "main_response = requests.get(main_url)\n",
    "\n",
    "main_soup = BeautifulSoup(main_response.content, \"html.parser\")\n",
    "\n",
    "# Create a set to store the URLs. Set's are imutabel and great for the task.\n",
    "url_set = set()\n",
    "\n",
    "# Create a list to store the sets in\n",
    "url_header_filename_list = []\n",
    "\n",
    "# Select all <a> tags with class \"elementor-sub-item\"\n",
    "links = main_soup.select(\"a.elementor-sub-item\")\n",
    "\n",
    "# Now \"links\" is a list of all <a> tags with the class \"elementor-sub-item\"\n",
    "# Iterate over each link and extract the url, the header and convert the header to \n",
    "# a filename.\n",
    "for link in links:\n",
    "    url = link.get(\"href\")\n",
    "    # The text describing the link will be the header for the document.\n",
    "    header = link.text  # or link.get_text()\n",
    "    # Convert the header text into snake_case \n",
    "    file_name = link.text.lower().replace(\" \", \"_\").replace(\".\",\"\")\n",
    "    # print(url, text)\n",
    "\n",
    "    # Clean up file names\n",
    "    for source, translate in translate_dict.items():\n",
    "        file_name = file_name.replace(source, translate)\n",
    "\n",
    "\n",
    "    # Limit the search to only contain the NBV's related to diabetes melitus\n",
    "    # Check if the URL starts with \"https://endocrinology.dk/nbv/diabetes-melitus/\" \n",
    "    # and is not equal to \"https://endocrinology.dk/nbv/diabetes-melitus/\"\n",
    "    if url.startswith(\"https://endocrinology.dk/nbv/diabetes-melitus/\") and url != \"https://endocrinology.dk/nbv/diabetes-melitus/\":\n",
    "        # Add the URL to the set\n",
    "        if url not in url_set:\n",
    "            url_set.add(url)\n",
    "            # print(url, header, file_name)\n",
    "            # Add the URL and text to the list\n",
    "            url_header_filename_list.append((url, header, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://endocrinology.dk/nbv/diabetes-melitus/type-1-diabetes-mellitus/', '1. Type 1 Diabetes', '1_type_1_diabetes'), ('https://endocrinology.dk/nbv/diabetes-melitus/behandling-og-kontrol-af-type-2-diabetes/', '2. Type 2 Diabetes', '2_type_2_diabetes'), ('https://endocrinology.dk/nbv/diabetes-melitus/monogenetisk-diabetes/', '3. Monogenetisk diabetes', '3_monogenetisk_diabetes'), ('https://endocrinology.dk/nbv/diabetes-melitus/diabetisk-ketoacidose-og-hyperosmolaer-hyperglykaemi/', '4. Diabetisk ketoacidose og hyperosmolær hyperglykæmi', '4_diabetisk_ketoacidose_og_hyperosmolaer_hyperglykaemi'), ('https://endocrinology.dk/nbv/diabetes-melitus/den-indlagte-patient-med-diabetes/', '5. Den indlagte patient med diabetes', '5_den_indlagte_patient_med_diabetes'), ('https://endocrinology.dk/nbv/diabetes-melitus/diabetes-og-kirurgi/', '6. Diabetes og kirurgi', '6_diabetes_og_kirurgi'), ('https://endocrinology.dk/nbv/diabetes-melitus/diabetes-og-graviditet/', '7. Præeksisterende diabetes og graviditet', '7_praeeksisterende_diabetes_og_graviditet'), ('https://endocrinology.dk/nbv/diabetes-melitus/diabetisk-neuropati/', '8. Diabetisk Neuropati', '8_diabetisk_neuropati'), ('https://endocrinology.dk/nbv/diabetes-melitus/den-diabetiske-fod/', '9. Diabetisk Fodsygdom', '9_diabetisk_fodsygdom'), ('https://endocrinology.dk/nbv/diabetes-melitus/kontinuerlig-glukosemaaling-cgm-og-flash-glukosemaaling-fgm-til-boern-unge-og-voksne/', '10. Kontinuerlig glukosemåling (CGM)', '10_kontinuerlig_glukosemaaling_(cgm)'), ('https://endocrinology.dk/nbv/diabetes-melitus/ketoacidose/', '1. Diabetisk ketoacidose', '1_diabetisk_ketoacidose')]\n"
     ]
    }
   ],
   "source": [
    "print(url_header_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping each guideline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_list(list_of_urls:list):\n",
    "    \"\"\"\n",
    "    This helper function test if a given list is a) not empty and b) contains\n",
    "    \"\"\"\n",
    "    # Assert that the list is not empty\n",
    "    assert list_of_urls, \"The list is empty.\"\n",
    "\n",
    "    # Assert that each item in the list has exactly three values and none of them are empty\n",
    "    for i, item in enumerate(list_of_urls):\n",
    "        assert len(item) == 3, f\"Row {i} does not have exactly three values.\"\n",
    "        empty_values = [j for j, value in enumerate(item, start=1) if not value]\n",
    "        assert not empty_values, f\"Row {i} has empty values at positions {empty_values}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_guidelines(list_of_guidelines:list, output_directory:str):\n",
    "    \"\"\"\n",
    "    Scrapes all guidelines from the Danish endocrine society given a list with URL's, \n",
    "    headers and file names. \n",
    "    Returns a file writen with the filenames.\n",
    "    input\n",
    "    list_of_guidelines(list):   A list containing three items:    \n",
    "                                URL of the page                              \n",
    "                                The header as text (will be inserted into the document)                 \n",
    "                                The filename that the output file should be saved as\n",
    "    output_directory(str):      Where directory where the files are saved\n",
    "    \n",
    "    output\n",
    "    A file      :   A file named after the filename containing all the text from a guideline.\n",
    "    \"\"\"\n",
    "    header_vars = [\"h1\", \"h2\", \"h3\"]\n",
    "    \n",
    "    for guideline in list_of_guidelines:\n",
    "        # get the url from the guideline\n",
    "        url = guideline[0]\n",
    "        # create a html request\n",
    "        response = requests.get(url)\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # output_file = \"../data/endocrinology_guidelines_type_2_diabetes.txt\"\n",
    "        output_file = f\"{output_directory}/{guideline[2]}.txt\"\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            # Write the header guideline as level 1\n",
    "            f.write(f\"#{guideline[1]}\\n\")\n",
    "            # Otherwise traverse through all headers and write to the file\n",
    "            for header in soup.find_all(header_vars):\n",
    "                for elem in header.next_siblings:\n",
    "                    if elem.name == header_vars[0]:\n",
    "                        f.write(f\"# {elem.get_text()}\\n\")\n",
    "                    elif elem.name == header_vars[1]:\n",
    "                        f.write(f\"## {elem.get_text()}\\n\")\n",
    "                    elif elem.name == header_vars[2]:\n",
    "                        f.write(f\"### {elem.get_text()}\\n\")\n",
    "                    # Write the paragraphs, if it is not the last paragraph, write it out\n",
    "                    elif (\n",
    "                        elem.name == \"p\" and elem.next_sibling and elem.next_sibling.name == \"p\"\n",
    "                    ):\n",
    "                        f.write(elem.get_text() + \"\\n\")\n",
    "                    else:\n",
    "                        f.write(elem.get_text() + \"\\n\\n\")\n",
    "        \n",
    "    print(f\"Wrote {len(list_of_guidelines)} guidelines to {output_directory}.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 11 guidelines to ../data.\n"
     ]
    }
   ],
   "source": [
    "scrape_guidelines(url_header_filename_list, \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the website\n",
    "url = \"https://endocrinology.dk/nbv/diabetes-melitus/behandling-og-kontrol-af-type-2-diabetes/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local header variables\n",
    "header_vars = [\"h1\", \"h2\", \"h3\"]\n",
    "output_file = \"../data/endocrinology_guidelines_type_2_diabetes.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for header in soup.find_all(header_vars):\n",
    "        for elem in header.next_siblings:\n",
    "            if elem.name == header_vars[0]:\n",
    "                f.write(f\"# {elem.get_text()}\\n\")\n",
    "            elif elem.name == header_vars[1]:\n",
    "                f.write(f\"## {elem.get_text()}\\n\")\n",
    "            elif elem.name == header_vars[2]:\n",
    "                f.write(f\"### {elem.get_text()}\\n\")\n",
    "            elif (\n",
    "                elem.name == \"p\" and elem.next_sibling and elem.next_sibling.name == \"p\"\n",
    "            ):\n",
    "                f.write(elem.get_text() + \"\\n\")\n",
    "            else:\n",
    "                f.write(elem.get_text() + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
